{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c589f8bd-bc45-40bf-ba25-266d249c4b3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Guía 2 - Regresión Lineal\n",
    "\n",
    "En este notebook comenzamos a trabajar en los problemas de **Regresión**, una de las tareas más importantes dentro del Aprendizaje Supervisado (dentro, a su vez, del gran área de Aprendizaje Automático). Un problema de regresión consiste en aprender a predecir una *etiqueta* *Y* continua o cuantitativa. a partir de un conjunto de atributos (también utilizaremos variables predictoras o *features*) **X** - que pueden ser uno, dos, o muchos más - tomando como muestra un conjunto de instancias. El modelo más común de regresión es la regresión lineal. Los modelos lineales se encuentran entre los modelos más simples, pero siguen siendo extremadamente comunes y útiles. Tienen algunas propiedades analíticas simples y son extremadamente fáciles de entrenar e interpretar. Además, son la base para un montón de modelos más complejos y modernos. Su importancia no debe ser subestimada.\n",
    "\n",
    "## 1. Regresión Lineal - 1D\n",
    "\n",
    "En la materia Introducción a la Ciencia de Datos ya han tenido un primer acercamiento a la regresión lineal. Aquí vamos a hacer un repaso de los principales conceptos que utilizaremos. Supongamos que queremos predecir una variable cuantitativa $Y$ como función de una única variable (por ahora, asumimos también cuantitativa) $X$. El modelo lineal asume que entre esas variables existe una relación del tipo\n",
    "\n",
    "$$Y \\approx \\beta_0 + \\beta_1 X,$$\n",
    "\n",
    "donde $\\beta_0$ y $\\beta_1$ son los parámetros del modelo, en este caso conocidos como *ordenada al origen* y *pendiente*, respectivamente. Estos parámetros son, hasta que no utilicemos los datos, parámetros desconocidos del modelo, que debemos *ajustar*. Otra forma que a veces pueden encontrar para el modelo lineal es la siguiente: \n",
    "\n",
    "$$Y = \\beta_0 + \\beta_1 X + \\epsilon, $$\n",
    "\n",
    "donde $\\epsilon$ es un término de error del modelo. A primera vista, este término puede ser muy confuso, pero esperamos que pronto quede claro qué significa. Notar que, en cualquiera de las dos formas, la variable predictora $X$ aparece de forma *lineal*, es decir, es decir, no está elevada al cuadrado, dentro de una raíz cuadrada, dentro de un seno, etc. Veremos en clases posteriores que este modelo es mucho más flexible de lo que parece. Tal vez les sorprenda leer ahora que podemos utilizar el modelo lineal para obtener relaciones no-lineales. \n",
    "\n",
    "**Referencias útiles**:\n",
    "\n",
    "* Capítulo 3 de *An Introduction to Statistical Learning*. Lo pueden obtener [aquí](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf).\n",
    "* [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/limo.html)\n",
    "\n",
    "\n",
    "**Repaso**\n",
    "\n",
    "1. ¿Cuáles son las ventajas de utilizar un modelo lineal?¿Y las desventajas?\n",
    "1. ¿Cuáles son las hipótesis del modelo lineal? Si no se cumplen, ¿significa que no podemos usar una regresión?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb95e3-5e7e-4530-b091-3358e66916d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Dataset Sintético\n",
    "\n",
    "Vamos a comenzar generando un dataset sintético. Esto quiere decir que vamos a conocer la verdadera relación entre nuestra variable objetivo $Y$ y nuestra variable predictora $X$. Esto NO es lo común, pero lo hacemos para que puedan ver el efecto de algunas características del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71902a7-35aa-4f82-9b3c-46b77c49abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa075d-df87-41ca-a046-7bf7116e3e25",
   "metadata": {},
   "source": [
    "La siguiente celda genera nuestro dataset sintético. Por ahora, serán 1000 puntos provenientes de una relación lineal 1-D de la forma $y = 3x - 2$. Asegúrate de identificar correctamente la pendiente ($\\beta_1$) y la ordenada al origen ($\\beta_0$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba77c32-443d-49c9-8622-c54aa564918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "X = np.linspace(-2,3,n)\n",
    "y_real = 3*X - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0b23a-955c-4bf1-bbcb-08538c4c374b",
   "metadata": {},
   "source": [
    "Sin embargo, esta relación no es muy realista, ya que en cualquier proceso de medición suele introducirse *ruido*. ¿Dónde se origina ese ruido? Bueno, podríamos escribir mucho al respecto, desde detalles técnicos hasta aspectos filosóficos. Por ahora vamos a decir que depende de cada proceso, a veces lo podemos reducir, a veces no. Vamos a experimentar introduciendo ruido gaussiano, de forma de acercanos a un proceso de medición realista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ed326-c8ea-423c-9414-0123a87b3ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2022)\n",
    "alpha = 1\n",
    "y = y_real + alpha*np.random.randn(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0260eab9-38ce-46e3-a3e7-f435b04c748f",
   "metadata": {},
   "source": [
    "Graficamos los puntos obtenidos junto con la curva teórica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f7839-ed52-4d78-985e-8fcd035da9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,y, s=2, alpha=0.5, label='Datos Medidos')\n",
    "plt.plot(X, y_real, '--',label='Curva Teórica', c='r')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1598747a-6532-450c-80cc-7cbf91dbcff4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Notar que, si bien los puntos no están sobre la línea teórica - debido al ruido -, la relación lineal parece mantenerse muy bien.\n",
    "\n",
    "**Ejercicio:** jugar con el código introduciento diferentes niveles de ruido modificando la variable `alpha`. ¿Cuándo crees, a simple vista, que la relación lineal ya queda oculta por el ruido?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364317a-ed1f-4c82-a188-76808d76eb23",
   "metadata": {},
   "source": [
    "### 1.1 Regresión lineal con SciPy\n",
    "\n",
    "Ahora vamos a hacer como si no conociéramos la relación entre $X$ e $y$ - nos olvidamos por un rato que sabemos cómo se generaron los datos - e intentaremos obtener la pendiente y ordenada al origen. Estos experimentos, donde generamos datos de una manera controlada, suelen ser muy útiles para familiarizarse con nuevos modelos y metodologías. De hecho, muchos paquetes, por ejemplo Scikit-Learn, vienen con funcionalidades para generar datasets sintéticos.\n",
    "\n",
    "Para obtener los parámetros vamos a utilizar SciPy. Por ahora no entraremos en detalles sobre cómo funciona, solamente lo utilizaremos. Recomendamos consultar la [documentación de la función `stats.linregress`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a4f4cc-84b7-4ffb-9052-9be971ed46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89490ae5-1c3e-47f2-a327-58924e2524e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.linregress(X,y)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb0830-be19-4b4d-9f90-f2ec716646f4",
   "metadata": {},
   "source": [
    "Para los que estén acostumbrados a trabajar con R, verán que estos resultados son muy parecidos a los que suelen encontrar. Devuelve la pendiente `slope`, la ordenada al origen `intercept`, el `rvalue`, el `pvalue`, la desviación estándar de la estimación de la pendiente`stderr` y la desviación estándar de la estimación de la ordenada al origen, `intercept_stderr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6332cb9-7a38-4d1c-9bb9-397c6d96dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.slope)\n",
    "print(res.intercept)\n",
    "print(res.rvalue)\n",
    "print(res.pvalue)\n",
    "print(res.stderr)\n",
    "print(res.intercept_stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a316d1c-3a3d-4c84-8835-8e7b86a650e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "¿Qué son esos valores? Los dos primeros son autoexplicativos, son los parámetros que buscamos. Están bastante cerca de los valores reales (3.01 vs 3, -1.99 vs -2). \n",
    "\n",
    "Veamos el resultado gráficamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21de9ac-ed5a-4a73-91c7-762e72ce1052",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,y, s=2, alpha=0.5, label='Datos Medidos')\n",
    "plt.plot(X, y_real, '--',label='Curva Teórica', c='r')\n",
    "plt.plot(X, X*res.slope + res.intercept, '--', lw=2, label='Curva Obtenida (SciPy)', c='g')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cebc2f-6726-4a31-97ec-1d4cea3d763b",
   "metadata": {},
   "source": [
    "El ajuste parece ser muy bueno. ¿Estás de acuerdo?\n",
    "\n",
    "**Ejercicio:** modificar los valores de `n` y `alpha` un par de veces (a mano) y observar cómo se modifican esos valores.\n",
    "\n",
    "Si te interesa conocer más en profundidad esos parámetros, te recomendamos que mires el notebook de Extras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b975cd5-c8e0-4e63-a742-b8f1a7e23e08",
   "metadata": {},
   "source": [
    "No hemos sido muy rigurosos en las definiciones sobre la regresión lineal y los parámetros obtenidos. ¿Por qué?¿Es porque no son importantes?¡Para nada, son muy importantes! Pero ahora veremos otro enfoque, más típico de la comunidad de Aprendizaje Automático. Desde ya, aclaramos que este enfoque no es mejor ni peor, sino complementario. Un buen científico de datos sabe cuando utilizar uno u otro.\n",
    "\n",
    "Empecemos notando algo. Cualquier método para ajustar datos - por ejemplo, el de regresión lineal que acabamos de usar - arranca con ciertos postulados sobre las características de esos datos. Para la regresión lineal que acabamos de usar alguno de estos son linealidad, normalidad, homocedasticidad, independencia, ausencia de multicolinealidad, etc. (pueden leer más [aquí](https://christophm.github.io/interpretable-ml-book/limo.html) o en la página de Wikipedia sobre regresión lineal). Cuando estas condiciones se cumplen, el método es óptimo, y los resultados que se desprenden del método tienen total validez (por ejemplo, cuando calculamos los intervalos de confianza). Entonces, antes de ajustar una regresión lineal, deberíamos chequear si esas hipótesis se cumplen. Sin embargo, salvo en contadas ocasiones, es muy difícil tener absoluta certeza de que así sea. En general, no hay ningún motivo para suponer que esas condiciones se cumplan exactamente y, en muchos casos, ni siquiera aproximadamente. ¿Entonces significa que no podemos usar el método? Por suerte, no. Si no se cumplen, eso no significa que el método sea malo. Probablemente haya uno mejor - que en general no sabemos cuál es - y debemos tener particular cuidado con las conclusiones estadísticas que desprendamos del método. Además, exiten  métodos que se proponen con muy pocas hipótesis y que no tienen garantía de optimalidad teórica. Otros métodos son óptimos en condiciones muy generales, pero solo cuando el tamaño de muestra tiende a infinito (es decir, cuando es muy grande nuestro conjunto de datos). En el mundo real, no hay ningún método que sea mejor que todos los demás en todos los casos.\n",
    "\n",
    "Pero hay algo más que también es importante diferenciar. Algunas veces, cuando estamos estudiando cierto fenómeno, nuestro objetivo principal no es modelar su naturaleza y entenderlo, sino simplemente tener poder predictivo sobre lo que va a ocurrir. Entonces, ¿qué podemos hacer en este mundo de hipótesis, métodos y objetivos aparentemente disímeles? Un enfoque complementario - típico de la comunidad de Aprendizaje Automática y expresado de manera simplificada - es probar un método y \"si funciona, funciona\". Pero, ¿cuándo un método funciona? Cuando tiene **poder predictivo**. Nuestro objetivo principal ya no va a ser modelar y comprender la realidad, sino simplemente tener buenas predicciones.\n",
    "\n",
    "Vamos a explorar este enfoque a continuación. Pero no queremos dejar de recalcar que ambos enfoques son complementarios y para nada excluyentes, por lo que no es necesario caer en falsas dicotomías. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de11ea0-cecf-41ff-8493-2d06ee2beea9",
   "metadata": {},
   "source": [
    "### 1.2 Regresión lineal con Scikit-Learn\n",
    "\n",
    "\n",
    "Vamos a ajustar estos datos con la regresión lineal de Scikit-Learn. **Es prácticamente obligatorio que consulten la [documentación sobre regresión lineal de esa librería](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).**\n",
    "\n",
    "En general, el uso de cualquier modelo de Aprendizaje Automático de Scikit-Learn sigue estos pasos.\n",
    "\n",
    "1. Definición de un objeto modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72943aa5-cf84-4b98-adfd-2b4b4a982d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "type(linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e2d84-faf2-47a4-b2df-ebe368846567",
   "metadata": {},
   "source": [
    "2. Ajuste a los datos (`.fit(X,y)`). \n",
    "\n",
    "**Nota:** cuando trabajen con un solo atributo (X tiene un solo atributo), se van a topar con un error típico. Scikit-Learn espera que X tenga la forma de *número de instancias* x *número de atributos*, Entonces, debemos llevar X a esa forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96dcfe6-fdd1-471f-a435-d55b89e004b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "X = X.reshape(-1,1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5605f74d-fa27-4b67-99d2-90528373789d",
   "metadata": {},
   "source": [
    "Ya podemos ajustar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b7614-026b-4cef-b42a-4cc9ed9267e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b0486-a245-4bbf-acb2-f9572779cadf",
   "metadata": {},
   "source": [
    "Los parámetros del ajuste están en `linear_model.coef_` y `linear_model.intercept_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef336618-9d14-42ab-ab61-a551832ee8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linear_model.coef_, linear_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03431ff-716b-4df6-8861-ce8d997a1c15",
   "metadata": {},
   "source": [
    "Notar que son, salvo error de redondeo, los mismos valores que los devueltos por SciPy. Sin embargo, la pendiente es parte de un `array`... Eso es una pista de algo que se viene después. ¿Y el $R^2$, p valor, desviaciones estándar, etc.? Desaparecieron... Scikit-Learn no devuelve nada del estilo. Entonces, ¿Cómo podemos hacer para saber si el ajuste es bueno?\n",
    "\n",
    "En primer lugar, vamos otra cosa que podemos hacer con el objeto `linear_model`. Podemos hacer predicciones.\n",
    "\n",
    "3. Predicciones (`.predict(X)`). \n",
    "\n",
    "Todos los modelos de Scikit-Learn tienen un método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a00e801-4c95-4016-8069-7627cf29d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f0eb88-e752-4b3c-b963-b330ae1e5d35",
   "metadata": {},
   "source": [
    "Nuevamente, veamos el resultado gráficamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123560c-c21f-4a29-8e5d-b261a125616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,y, s=2, alpha=0.5, label='Datos Medidos')\n",
    "plt.plot(X, y_real, '--',label='Curva Teórica', c='r')\n",
    "plt.plot(X, y_pred, '--', lw=2, label='Curva Obtenida (Scikit-Learn)', c='g')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a96e4a-b30a-4388-b65d-ce5712161efc",
   "metadata": {},
   "source": [
    "El ajuste evidentemente es tan bueno como el de SciPy, pero no tenemos ninguna métrica para evaluarlo. Podríamos calcular las mismas métricas de SciPy nosotros, pero podemos hacer algo más fácil y, en muchos casos, eficiente. Vamos a hacer una **Evaluación del modelo**.\n",
    "\n",
    "### 1.3 Evaluación\n",
    "\n",
    "La evaluación de un modelo es algo tan importante como su entrenamiento. Durante la cursada haremos mucho hincapié en esto. En un problema de regresión, lo primero que podemor hacer es comparar las predicciones obtenidas con los valores a predecir. Si el modelo está haciendo un buen trabajo, éstas deberían estar agrupadas alrededor de la identidad (la recta diagonal $y=x$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382b402-a351-40eb-8247-45b6c786f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y,y_pred, alpha=0.75, s=1)\n",
    "plt.plot([-10,10],[-10,10], ls='--', c='r', label='identidad')\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('y_pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ffd46-aa4e-4ddf-94b7-5f8f83ddca03",
   "metadata": {},
   "source": [
    "#### Métricas\n",
    "\n",
    "Otra forma de evaluar un modelo - sumamente importante y útil - es calcular una métrica de desempeño. En los problemas de regresión es común utilizar métricas como el **error cuadrático medio**:\n",
    "\n",
    "$$ MSE(y, \\hat y) = \\frac{1}{N}\\sum_{i=1}^N (y_i - \\hat y_i)^2 $$\n",
    "\n",
    "donde $N$ es la cantidad de instancias e $\\hat y$ son las predicciones del modelo. Notar que estamos comparando cada dato y predicción de manera individual.\n",
    "\n",
    "**Para Pensar:** si tuvieras que decir de qué parámetros del modelo depende el error cuadrático medio (MSE), ¿qué dirías?\n",
    "\n",
    "Otra métrica muy utilizada, y un poco más amigable, es la **raiz del error cuadrático medio**, ya que tiene las mismas unidades que la variable obejtivo $y$\n",
    "\n",
    "$$ RMSE(y, \\hat y) = \\sqrt{MSE(y, \\hat y)} $$\n",
    "\n",
    "Notar que la evaluación de un modelo siempre consiste en comparar los valores predichos $\\hat y$ y los valores objetivo $y$, utilizando alguna métrica. ¡Esto será cierto a lo largo del curso!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd0325-7dc2-4cef-9c79-415813f253a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def root_mean_squared_error(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(f'MSE = {mean_squared_error(y,y_pred)}')\n",
    "print(f'RMSE = {root_mean_squared_error(y,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d922f40-5cfa-4c32-95df-db07f3f75bde",
   "metadata": {},
   "source": [
    "**Ejercicio (opcional para cuando terminen de leer el notebook)**: programar una función que calcule el error cuadrático medio dadas las etiquetas y los valores predichos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106c600-9b2f-4ebf-a890-9a4dfdd3f669",
   "metadata": {},
   "source": [
    "En este caso, por una cuestión de magnitudes, dan muy parecido. Modifica `alpha` (por ejemplo, 2, 5 y 10) y vuelve a correr. ¿Qué ocurre con el RMSE? También observa el gráfico y trata de ver si puedes interpretar el valor del RMSE gráficamente.\n",
    "\n",
    "Existen muchas métricas para evaluar un modelo de regresión. Cuál será conveniente dependerá del objetivo de nuestro análisis. No hemos profundizado en esto, pero notar que, en este caso, MSE es la misma métrica que utiliza Scikit-Learn (y SciPy) para obtener los coeficientes del ajuste lineal (comentario sobre esto hacia el final del notebook). Es decir, estamos evaluando con la misma métrica que usamos para entrenar. Muchas veces esto **no será así.**\n",
    "\n",
    "#### Residuos\n",
    "\n",
    "Un último análisis que podemos hacer es el análisis de residuos. Esto consiste en ver la diferencia entre nuestra predicción y el valor real. El residuo se define como \n",
    "\n",
    "$$ \\text{res} = y - \\hat y $$\n",
    "\n",
    "Dos gráficos usuales que podemos hacer con los residuos son:\n",
    "\n",
    "1. Su histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7728b72-f2d2-4dc1-b309-3b7e281e41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = y - y_pred\n",
    "plt.hist(res, bins = 20, rwidth = 0.9)\n",
    "plt.xlabel('res')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2290a5-fe62-4e6f-87de-300124ef156e",
   "metadata": {},
   "source": [
    "En el enfoque clásico de regresión lineal, los residuos deben tener media cero y estar distribuidos normalmente. En la práctica, esto no suele suceder, ya que son necesarias muchas hipótesis para que así sea. Sin embargo, observar este gráfico puede darnos indicios de la calidad de nuestro modelo.\n",
    "\n",
    "**Para pensar:** ¿Cuál te parece que es el *ancho* de esta distribución y con qué valor visto puede estar relacionado?\n",
    "\n",
    "2. También podemos graficar la relación entre el residuos y el valor correspondiente de $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d1cce-99a9-43ed-96ce-dde8e9d188c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X, res)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('res')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696b3dc-5b28-43a8-ac1c-8a2b59419444",
   "metadata": {},
   "source": [
    "Este gráfico también suele ser muy útil, ya que nos da una idea sobre en qué regiones de X el modelo anda mejor y en cuáles peor. A medida que hay más atributos predictores, este gráfico es más difícil de interpretar.\n",
    "\n",
    "## 2. Regresión Lineal - 2D\n",
    "\n",
    "La generalización de la regresión lineal a más atributos es muy sencilla. Por ejemplo, para dos atributos, $X_1$ y $X_2$, la forma es\n",
    "\n",
    "$$Y \\approx \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2.$$\n",
    "\n",
    "Y, en el caso de $p$ variables predictoras, \n",
    "\n",
    "$$Y \\approx \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + ... + \\beta_p X_p.$$\n",
    "\n",
    "Es decir, debemos encontrar una pendiente por cada atributo, pero sigue siendo una única ordenada al origen.\n",
    "\n",
    "Ahora, replicaremos el mismo análisis, pero para una relación lineal con dos atributos, $y = -3x_1 + 2x_2 + 4$. Nuevamente, sumaremos algo de ruido para hacerlo más realista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89984720-5ef3-438a-a07f-1d404aca96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "x1 = np.random.rand(n)\n",
    "x2 = np.random.rand(n)\n",
    "y = -3*x1 + 2*x2 + 4 + 0.25*np.random.randn(n)\n",
    "# y = 10*(x1 - 0.5)**2 + 10*(x2-0.5)**2 + 0.1*np.random.randn(n) # Da como resultado una superficie curva, tipo cuenco.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2d396-3563-4463-a776-0e932d2ff5c5",
   "metadata": {},
   "source": [
    "Visualizamos. El código es un poco más complejo, no te preocupes si no lo entiendes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ad19b-fc44-4a01-8325-875704e6de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_3d_scatter(x1, x2, y, ax=None, fig = None):\n",
    "    if (fig is None) and (ax is None):\n",
    "        fig = plt.figure(figsize = (8,6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(x1, x2, y)\n",
    "\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_zlabel('y')\n",
    "\n",
    "plot_3d_scatter(x1, x2, y, ax=None, fig = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be75999-f443-4ffc-96c8-8b0bfc1bc491",
   "metadata": {},
   "source": [
    "Creamos los atributos y hacemos un `train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b99c6e9-764f-4c6e-aaf6-3486d1da41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((x1,x2)).T\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599ac45b-d495-46b9-a5fb-add719b29255",
   "metadata": {},
   "source": [
    "Notar que tiene el `shape` que necesita Scikit-Learn. Definimos los modelos y entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0116ec2-8dda-4817-ad44-bbadf3259523",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e5bcb3-a50b-4c0f-b64f-bb1e6d35c3ea",
   "metadata": {},
   "source": [
    "Nuevamente, veamos qué aprendió. La regresión lineal obtiene **las pendientes** y la ordenada al origen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7339ae1-d029-4ab2-a3cb-ddac9b18cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linear_model.coef_, linear_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f2e9eb-739b-4dc2-97bd-b62bd121f388",
   "metadata": {},
   "source": [
    "En este caso, la curva que aproxima a los datos no es más una curva, sino una superficie. La siguiente función nos ayuda a graficar. Nuevamente, no se preocupen si no entienden del todo lo que hace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ae603-e2b9-4103-a2de-ef086cd95c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "def plot_3d_regressor(x1_min, x1_max, x2_min,x2_max, N, regressor, ax=None, fig = None):\n",
    "    x1 = np.linspace(x1_min,x1_max,N) \n",
    "    x2 = np.linspace(x2_min,x2_max,N)\n",
    "    X1, X2 = np.meshgrid(x1,x2)\n",
    "    \n",
    "    y = regressor.predict(np.array([X1.ravel(), X2.ravel()]).T)\n",
    "    Y = y.reshape(X1.shape)\n",
    "    \n",
    "    if (fig is None) and (ax is None):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    surf = ax.plot_surface(X1, X2, Y, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False, alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4f9a3-04b5-4239-a513-c8cb170c6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (6,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plt.title('Regresión Lineal')\n",
    "plot_3d_regressor(0, 1, 0, 1, 100, linear_model, ax, fig)\n",
    "plot_3d_scatter(x1, x2, y, ax, fig)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0e0a3-dd51-4974-b157-96aa42d45825",
   "metadata": {},
   "source": [
    "Nuevamente, podemos hacer una evaluación de los resultados. Empecemos haciendo las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13113039-5143-43b8-b7b1-ffc35901bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94454a09-9a12-4d63-b01b-dcfa3faad5af",
   "metadata": {},
   "source": [
    "Y repetimos la evaluación vista anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e27727-c040-4a62-ae61-0a0014e64e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y,y_pred, alpha=0.75, s=1)\n",
    "plt.plot([0,7],[0,7], ls='--', c='r', label='identidad')\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('y_pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b30e1-996c-4eec-a906-e2fba4175903",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE = {mean_squared_error(y,y_pred)}')\n",
    "print(f'RMSE = {root_mean_squared_error(y,y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3207add2-b997-4577-ba50-556e32282444",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = y - y_pred\n",
    "plt.hist(res, bins = 20, rwidth = 0.9)\n",
    "plt.xlabel('res')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a8e2b8-d5a3-4462-88b5-a206803727f0",
   "metadata": {},
   "source": [
    "Hasta acá vimos la aplicación de la regresión lineal a dos datasets sintéticos, uno con una variable predictora y otro con dos. Nada nos impide aplicar esta técnica a muchas más variables predictoras. La única diferencia es que ya no podremos visualizar la superficie obtenida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30024d51-698f-4961-a2ad-a14b4b584fd0",
   "metadata": {},
   "source": [
    "## 3. Ejercitación\n",
    "\n",
    "Vamos a aplicar lo visto sobre regresión lineal al dataset de Bicicletas Públicas de la Ciudad de Buenos Aires (EcoBici). Nuevamente, solamente vamos a utilizar los datos para el **año 2018**. \n",
    "\n",
    "El análisis que haremos es muy similar al que se encuentra en el [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) de Jake VanderPlas sobre el dataset de pasos de bicicletas en el Puente Fremont de Seattle, EEUU, que pueden encontrar en la sección \"In Depth: Linear Regression\".\n",
    "\n",
    "### Consigna\n",
    "\n",
    "El objetivo es ajustar - o entrenar - un modelo lineal que prediga la cantidad de viajes en bicicleta en un dado día.\n",
    "\n",
    "**Preliminares:**\n",
    "\n",
    "1. ¿En qué contexto puede ser interesante abordar ese problema?\n",
    "1. Piensa y evalúa qué atributos crees que pueden ser buenos predictores. Para ello, puedes volver al notebook de EDA sobre este dataset y observar la serie de tiempo de viajes por día. Mira qué características de la serie te llaman la atención.\n",
    "\n",
    "**Ejecución:**\n",
    "\n",
    "1. Abre los datos provistos en 'IAA_Guia_2_data.csv'. Cuando abras los datos, ten en cuenta que es importante que puedas trabajar con fechas. Si quieres saber cómo hemos llegado a ese dataset, puedes mirar el notebook 'IAA_Guia_2_PrePro_Dataset.ipynb'.\n",
    "1. Agrega al DataFrame obtenido atributos que puedan llegar a ser buenos predictores (además de los que puedas encontrar). Recomendamos probar con:\n",
    "    1. Una variable binaria que indique si se trata de un día de semana o de fin de semana.\n",
    "    1. Una variable binaria que indique si se trata de un mes de vacaciones o no.\n",
    "    \n",
    "1. Agrupa las variables predictoras en una variable `X` y la variable a predecir en una variable `y`.\n",
    "1. Entrena un modelo lineal. Observa los coeficientes obtenidos e interpreta.\n",
    "1. Haz una evalución de los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ad82a-3c15-42fc-813c-a5a622cae611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
