{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "igUfRozJelVA"
      },
      "source": [
        "# Clasificación Avanzada"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wLr0P1E0elVD"
      },
      "source": [
        "En esta guia exploraremos casos mas avanzados de clasificación: \n",
        "- Clasificación Desbalanceada: Cuando una clase esta sobre-representada en la muestra de entrenamiento.\n",
        "- Clasificación Multiclase: Cuando hay mas que dos clases.\n",
        "\n",
        "Haremos particular foco en las métricas utilizadas para estos casos.\n",
        "\n",
        "Para esto, utilizaremos un dataset muy popular, de dígitos escritos a mano, conocido como MNIST.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TeGzN8M-elVF"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lGA2KtcUelVG"
      },
      "source": [
        "Vamos a usar un set de datos clásico de Machine Learning, los números de MNIST. Se trata de 70 000 imágenes pequeñas de dígitos escritos a mano. El \"target\" de cada uno de estos dígitos es el número que representan.\n",
        "\n",
        "Este set de datos es tan común, que en `sklearn` hay una función que permite bajarlos directamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3hXe29ielVG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "# Carga el dataset desde https://www.openml.org/d/554\n",
        "X, y = fetch_openml(\n",
        "    \"mnist_784\", version=1, return_X_y=True, as_frame=False, parser=\"pandas\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uu-VpbLRHMQA"
      },
      "source": [
        "**Ejercicio:**\n",
        "* Analice el `shape` de los features y el target, asi como el tipo de datos de estos. Mire los valores minimos y maximos que toman los \"píxeles\". \n",
        "* Normalice el dataset para que los features vayan de 0 a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4Qr7eoGhwE5",
        "outputId": "1235b017-635f-4946-94f5-5fc22c833661"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "38SAo8oPHOcm"
      },
      "source": [
        "# Utilidades\n",
        "La siguiente funcion le sera util para graficar los digitos:\n",
        "1. Lleva cada pixel a un numero entero entre 0 y 255 (256 bit),\n",
        "2. Transforma el vector en una matriz de 28 x 28. \n",
        "3. Por ultimo, grafica la matriz en escala de grises (0= blanco, 255=negro)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmR3ZmLEid6b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.cm as cmap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_digit(data, subplot=plt):\n",
        "    image = (data.reshape(28, 28)*255).astype(int)\n",
        "    subplot.imshow(image, cmap = cmap.binary,\n",
        "               interpolation=\"nearest\")\n",
        "    subplot.axis(\"off\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fk15o44pH9Fz"
      },
      "source": [
        "Examinemos algunos ejemplos. Iteraremos en los digitos del 0 al 8, y tomaremos el primer punto del dataset que corresponde a ese target para graficarlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "MZSCpcGRk54r",
        "outputId": "2c9d2d62-54a7-4388-9455-c11ecb150ce0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "for numero in range(0,10):\n",
        "  sp = plt.subplot(2, 5, numero + 1)\n",
        "  idx = (y==str(numero)).argmax()\n",
        "  plot_digit(X[idx], subplot=sp)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HU0en9CxpgS1"
      },
      "source": [
        "## Clasificacion Binaria desbalanceada\n",
        "\n",
        "Transformaremos este problema multiclase en un problema de clasificación binaria, en el que el objetivo es predecir si un digito es o no un cinco."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CuVyBA-yIQEJ"
      },
      "source": [
        "**Ejercicio**\n",
        "* A continuación, cree un nuevo vector de target que consista en `1` si el target es un `'5'` o `0` si no lo es.\n",
        "\n",
        "(Puede utilizar otro digito si lo desea)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0afOXjO1n4rl"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UciBrvyrIkF7"
      },
      "source": [
        "**Ejercicio**\n",
        "* Separe una 10 mil puntos al azar del dataset para utilizar como evaluación\n",
        "\n",
        "*Nota: No es necesario separar un conjunto de validación, dado que podemos utilizar en su lugar las técnicas de validación cruzada vistas la clase anterior.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF-DhB4mqDIM"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3_Azgrx5I6fe"
      },
      "source": [
        "**Ejercicio**\n",
        "* Grafique la distribución de puntos de ambas clases en un histograma.\n",
        "* ¿Que fraccion de los puntos pertenecen a la clase positiva? ¿Que conclusión saca de ello?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "TOGDrtqkpevI",
        "outputId": "77e2c52a-2513-4160-d81e-053883851896"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CMWs4uM0JIaZ"
      },
      "source": [
        "**Ejercicio**\n",
        "* Instancie un regresor logístico\n",
        "* Utilice técnicas de validación cruzada para estimar la exactitud (*accuracy*) sobre datos no vistos anteriormente.\n",
        "* ¿Que tan bueno es el modelo? ¿Que porcentaje de aciertos alcanza?\n",
        "\n",
        "*Nota 1: En lugar de instanciar un `LogisticRegression()`, pruebe utilizando `SGDClassifier(loss='log_loss')` del mismo modulo `sklearn.linear_model`. Este es una implementación iterativa que usa descenso por gradiente, y puede converger mas rápido.*\n",
        "\n",
        "*Nota 2: La normalización para que los pixeles esten entre 0 y 1, en lugar de 0 y 255, si bien no era necesaria, ayuda al modelo a converger mas rápido, y le ahorra tiempo mirando la pantalla.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSiM9QdAelVH",
        "outputId": "86de325d-76e6-45ed-949c-49ca2944db4d"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_qdJdAaKSmC"
      },
      "source": [
        "**Ejercicio**\n",
        "* Como benchmark, considere un clasificador naïve que siempre dice que el número _no es un cinco_ (o la clase que haya elegido). ¿Que exactitud obtiene? \n",
        "* ¿Como cambia su respuesta anterior a que tan bueno es el modelo?\n",
        "\n",
        "*Nota: Para simplificar, puede medir la exactitud de este modelo sobre el conjunto de entrenamiento o de evaluación. La ausencia de parámetros del mismo nos asegura que no estamos sobreajustando ninguno de estos conjuntos, y la medicion es una buen estimador de su generalización*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJeEcSClrJWS",
        "outputId": "6f812091-f39b-47d8-844b-744ec339bd3b"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dZj06dTnLDml"
      },
      "source": [
        "### Matriz de Confusión y Análisis de Resultados\n",
        "\n",
        "Para analizar los resultados, en los casos desbalanceados la exactitud no suele ser una buena métrica a monitorear. Para entender mejor la performance, podemos usar las predicciones del modelo para calcular la Matriz de Confusión, que nos dice cuantos samples de cada clase han sido clasificados en cada clase:\n",
        "\n",
        "\n",
        "|     | Clase Pred 0 | Clase Pred 1 |\n",
        "| -------- | ------- | ------- |\n",
        "| **Clase Real 0**  | True Negative (TN) | False Possitive (FP) |\n",
        "| **Clase Real 1** | False Negative (FN) | True Possitive (TP) |\n",
        "\n",
        "\n",
        "Con esto, ademas de ver cada caso en particular, podemos calcular metricas que suelen ser de mucho interes:\n",
        "\n",
        "1. Precisión: $\\frac{TP}{TP + FP}$ Esta representa la fracción de elementos que predecimos como clase 1, efecivamente lo son. \n",
        "_\"Cuantos de los que digo que son cinco efectivamente lo son\"_\n",
        "\n",
        "2. Exhaustividad (_recall_): $\\frac{TP}{TP + FN}$ Representa la fracción de elementos de la clase 1 que hemos clasificado bien. \n",
        "_\"Cuantos cincos capturamos correctamente\"_\n",
        "\n",
        "3. F1-score: $\\frac{1}{F1} = \\frac{1}{2}(\\frac{1}{recall} + \\frac{1}{precision})$ El promedio armónico entre precisión y exhaustividad. Este es un numero siempre menor al menor de ambas cantidades, por lo que mejorarlo implica mejorar ambas métricas.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QX6nUIzGObFS"
      },
      "source": [
        "**Ejercicio**\n",
        "* Utilice técnicas de validación cruzada para obtener las predicciones sobre el conjunto de entrenamiento, cuando no se entrena sobre él (`sklearn.model_selection.cross_val_predict`).\n",
        "* Calcule la matriz de confusión (`sklearn.metrics.confusion_matrix` )\n",
        "* Calcule la precisión y exhaustividad a partir de la matriz de confusión, y compare con los valores obtenidos por las funciones implementadas en `sklearn.metrics`\n",
        "\n",
        "*Nota:*\n",
        "$$\n",
        "\\mathrm{precision} = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathrm{recall} = \\frac{TP}{TP + FN}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zdk1UjC2sZxh"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IG8WCsg6PG1w"
      },
      "source": [
        "### Analisis de errores\n",
        "\n",
        "Para analizar los errores obtenidos, es util mirar no solo el numero de equivocaciones, sino también con que confianza se equivocó. No es lo mismo clasificarlo no-cinco porque su probabilidad de ser cinco era 0.49, a porque la probabilidad era 0.0001, cuando en realidad si era cinco.\n",
        "\n",
        "Hagamos este análisis a continuación.\n",
        "\n",
        "**Ejercicio**\n",
        "* Utilice técnicas de validación cruzada para obtener las probabilidades predichas por el modelo sobre el conjunto de entrenamiento, cuando no se entrena sobre él.\n",
        "\n",
        "*Nota 1: `cross_val_predict` admite un argumento `method=` en el cual se puede elegir entre `predict`, `predict_proba`, `decision_function`, etc.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzN1gm9auQWr"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "c3y7UCswScxU"
      },
      "source": [
        "**Ejercicio**\n",
        "\n",
        "* Realice un histograma de la distribución de probabilidades.\n",
        "* Plotee encimados los histogramas de estas distribuciones para los samples que tienen target 5, y para los que no. ().\n",
        "* ¿Qué observa? ¿Qué conclusiones saca? ¿Cómo se podría mejorar?\n",
        "\n",
        "*Nota 1: Considere solo la probabilidad de pertenecer a la clase 5 (segunda columna), ignorando la probabilidad de no pertenecer a ella (primera columna).*\n",
        "\n",
        "*Nota 2: Puede realizar el `plt.hist` dos veces y se encimarán los graficos. Un `alpha=0.5` como argumento puede ayudar a ver los solapamientos, asi como un `density=True` puede ser util dado el desbalance entre clases. Experimente con el gráfico.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "6MZ07VNAsuHR",
        "outputId": "67d3e637-c063-4a79-ed9b-35239467ec53"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UmOrNkEITbXM"
      },
      "source": [
        "Por último, examinemos los números más problemáticos. \n",
        "\n",
        "**Ejercicio:**\n",
        "* Visualice, usando la función `plot_digits`, los 20 digitos cinco \"peor clasificados\", es decir aquellos que el modelo predijo que tienen la menor probabilidad de ser cinco. Para esto:\n",
        "  * Copie los arrays de cincos y sus probabilidades predichas a dos variables nuevas.\n",
        "  * Consiga los indices ordenados de menor a mayor probabilidad (pista: `np.argsort`)\n",
        "  * Plotee los cincos dados por los 20 primeros elementos de la lista ordenada de índices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aJxHpzQelVK"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN8PN8hBU5Q3"
      },
      "source": [
        "### Análisis del modelo\n",
        "\n",
        "Como bien sabemos, el regresor logístico ajusta un peso por cada feature, y si los features están normalizados, la magnitud de estos pesos indican la influencia del feature corespondiente en el resultado, algo conocido como _feature importance_. \n",
        "\n",
        "En el caso de imágenes, cada peso corresponde a un píxel. Por lo que si lo graficamos del mismo modo que hacemos a un píxel, podemos generar una suerte de _mapa de calor_ de los píxeles que mas influyen en el resultado.\n",
        "\n",
        "*Ejercicio*\n",
        "* Utilice la función `plot_digit` sobre los pesos del estimador entrenado, para visualizar la influencia de cada píxel en el resultado. Esto es de gran utilidad para entender el funcionamiento del modelo al clasificar.\n",
        "\n",
        "* Visualice el \"cinco promedio\", tomando el promedio pixel a pixel sobre todos los puntos correspondientes a un cinco y visualizando el resultado con `plot_digit`. Compare este resultado con el anterior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "CX_TOwGRVnvJ",
        "outputId": "bebd6170-1a4b-4f8e-c680-317a611f7a0d"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FCHHO_Ej1--W"
      },
      "source": [
        "# MultiClass\n",
        "\n",
        "Ahora volvamos al problema original, de clasificación multiclase. \n",
        "\n",
        "\n",
        "**Ejercicio**\n",
        "* Separe una 10 mil puntos al azar del dataset para utilizar como evaluación\n",
        "* Grafique la distribución de puntos sobre las clases en un histograma.\n",
        "* ¿Que fraccion de los puntos pertenecen a cada clase? ¿Que conclusión saca de ello?\n",
        "* Instancie un regresor logístico y entrénelo sobre el conjunto de entrnamiento. ¿Cuantos parámetros tiene el modelo? ¿Que `shape` tienen los coeficientes?\n",
        "\n",
        "*Nota 1: Por defecto, scikit-learn implementa una clasificación binaria de cada clase contra el resto, conocida como _one-vs-rest_. Al resultado de cada clasificador lo normaliza para obtener una probabilidad multiclase, en el que la suma de 1.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX4_fJ-tWoBU"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Eb890Wdbjid"
      },
      "source": [
        "\n",
        "**Ejercicio**\n",
        "* Utilice técnicas de validación cruzada para estimar la exactitud (*accuracy*) sobre datos no vistos anteriormente.\n",
        "* Utilice técnicas de validación cruzada para obtener las predicciones sobre el conjunto de entrenamiento, cuando no se entrena sobre él (`sklearn.model_selection.cross_val_predict`).\n",
        "* Calcule la matriz de confusión (`sklearn.metrics.confusion_matrix` ). Examine las diferencias respecto al caso binario.\n",
        "* Calcule la precisión y exhaustividad utilizando las funciones implementadas en `sklearn.metrics`. ¿Que error obtiene? ¿Porque? Pruebe utilizando el argumento `average=None`. ¿Cómo interpreta ese resultado?\n",
        "* Examine el resultado de la función `classification_report` del módulo `sklearn.metrics`. \n",
        "\n",
        "\n",
        "*Nota 2: El entrenamiento ya lleva más tiempo. Si no tiene tiempo de esperar, en vez de usar validación cruzada entrene en el conjunto de entrenamiento. Puede calcular las métricas tanto sobre el conjunto de entrenamiento como en el de evaluación (al fin y al cabo, es con fines educativos ;) )*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bat2V4BYX0H2",
        "outputId": "2b40b9fa-1206-495b-ba65-d5addf61d860"
      },
      "outputs": [],
      "source": [
        "# Tu turno ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4vKGJSvFab_R"
      },
      "source": [
        "# Formulario de Asistencia\n",
        "\n",
        "Obligatorio completar antes del Miercoles 7 de Junio a las 23:59\n",
        "[TBD]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
